# Time Reclamation App

Reclaim time wasted on social media by getting curated summaries instead of endless scrolling.

## âœ¨ Features

### ğŸ¯ Smart Content Curation
- **YouTube Channel Monitoring**: Automatically track and fetch new videos from your favorite channels
- **Intelligent Transcript Extraction**: Extract video transcripts in multiple languages (English, French, etc.)
- **Configurable Video Limits**: Control how many videos to process per channel

### ğŸ¤– AI-Powered Summarization
- **Multi-LLM Support**: Choose from various AI providers:
  - **Local Models**: LlamaCpp (GGUF models), Ollama (llama2, mistral, codellama, etc.)
  - **Cloud Providers**: Anthropic Claude (Haiku, Sonnet), OpenAI GPT (GPT-5, O4-mini)
- **Custom System Prompts**: Tailor summaries to your preferences (conversational, technical, brief, etc.)
- **Flexible Provider Selection**: Use different LLMs for different channels or content types

### ğŸ”Š Text-to-Speech Integration
- **Multiple TTS Engines**:
  - **Kokoro TTS**: High-quality neural voices (American/British English, multiple voice options)
  - **Piper TTS**: Lightweight, fast synthesis with multi-language support
- **Audio Summary Generation**: Convert text summaries into audio files for on-the-go listening
- **Voice Customization**: Choose from various voices and accents

### ğŸ“± Smart Notifications
- **Telegram Integration**: Receive summaries directly in your Telegram chat
- **Multi-Bot Support**: Configure multiple notification channels for different content types
- **Audio Delivery**: Get audio summaries sent directly to your messaging app

### ğŸ’¾ Efficient Caching & State Management
- **Local Caching**: Store transcripts and summaries to avoid redundant processing
- **SQLite Database**: Track processed videos and maintain state across runs
- **Incremental Updates**: Only process new content since last run

### ğŸ› ï¸ Developer-Friendly
- **CLI Interface**: Easy-to-use command-line tools for all operations
- **Modular Architecture**: Clean separation of concerns with pluggable providers
- **Extensible Design**: Easy to add new platforms, LLMs, or TTS providers
- **YAML Configuration**: Simple, human-readable configuration files

## ğŸ“‹ Requirements

- Python 3.8+
- FFmpeg (for audio processing)
- Optional: CUDA-capable GPU for faster local LLM inference

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/marouane-dev75/social-summarizer
cd social-summarizer

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create a `config.local.yml` file based on the example below:

```yaml
# Platform Configuration
platforms:
  youtube:
    enabled: true
    channels:
      - name: "TechChannel"
        scrap: true
        url: "https://www.youtube.com/@TechChannel"
        max_videos: 5
        language: "en"
        cache_folder: "cache_data/youtube_transcripts/tech_channel"
        summary:
          enabled: true
          llm_provider: "ollama_local"
          tts_provider: "kokoro_english"
          notification_provider: "personal_bot"
          system_prompt: |
            You are a YouTube video summarizer that creates a single flowing 
            paragraph in plain text, using natural speech-friendly language 
            without formatting, symbols, or markdown, presenting the main 
            topic followed by key points with smooth transitions and ending 
            with a conclusion.

# Notification Configuration
notifications:
  providers:
    - name: "personal_bot"
      type: "telegram"
      enabled: true
      config:
        bot_token: "YOUR_BOT_TOKEN_HERE"  # Get from @BotFather on Telegram
        chat_id: "YOUR_CHAT_ID_HERE"      # Your Telegram chat ID
        timeout_seconds: 30
        retry_attempts: 3

# LLM Configuration
llm:
  providers:
    # Local Ollama instance
    - name: "ollama_local"
      type: "ollama"
      enabled: true
      config:
        base_url: "http://localhost:11434"
        model: "llama2"  # or mistral, codellama, etc.
        timeout_seconds: 120
        generation_config:
          temperature: 0.7
          num_predict: 4000
          top_p: 0.9
          top_k: 40
        default_system_prompt: "You are a helpful AI assistant."
    
    # Cloud provider example (optional)
    - name: "claude_assistant"
      type: "anthropic"
      enabled: false
      config:
        api_key: "YOUR_ANTHROPIC_API_KEY"
        model: "claude-haiku-4-5"
        max_tokens: 4000
        temperature: 0.7

# TTS Configuration
tts:
  providers:
    - name: "kokoro_english"
      type: "kokoro"
      enabled: true
      config:
        voice: "af_alloy"  # Available: af_heart, af_alloy, af_bella, am_adam, etc.
        lang_code: "a"     # a = American English, b = British English
        repo_id: "hexgrad/Kokoro-82M"
        sample_rate: 24000
        output_dir: "cache_data/tts"
    
    - name: "piper_french"
      type: "piper"
      enabled: false
      config:
        model_path: "/path/to/fr_FR-siwis-medium.onnx"
        output_dir: "cache_data/tts"
```

### Usage

```bash
# Process YouTube channels and generate summaries
python main.py youtube process

# Test LLM provider
python main.py llm test --provider ollama_local --prompt "Hello, how are you?"

# Test TTS provider
python main.py tts test --provider kokoro_english --text "This is a test."

# Test notification
python main.py notify test --provider personal_bot --message "Test notification"

# View database info
python main.py db info

# Show version
python main.py version
```

## ğŸ“ Project Structure

```
TimeReclamation/
â”œâ”€â”€ main.py                          # Application entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # This file
â”‚
â”œâ”€â”€ src/time_reclamation/
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                      # Configuration management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ manager.py               # Config loader and validator
â”‚   â”‚   â”œâ”€â”€ config.yml               # Default configuration template
â”‚   â”‚   â””â”€â”€ config.local.yml         # User-specific configuration (gitignored)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ youtube/                 # YouTube platform implementation
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ service.py           # Main YouTube service
â”‚   â”‚       â”œâ”€â”€ channel_manager.py   # Channel operations
â”‚   â”‚       â”œâ”€â”€ transcript_fetcher.py # Transcript extraction
â”‚   â”‚       â”œâ”€â”€ cache_manager.py     # Caching logic
â”‚   â”‚       â”œâ”€â”€ summary_service.py   # Summary generation
â”‚   â”‚       â””â”€â”€ database.py          # YouTube-specific DB operations
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/              # External integrations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ llm/                     # LLM providers
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ interface.py         # LLM provider interface
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py           # LLM provider manager
â”‚   â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ llamacpp.py      # LlamaCpp implementation
â”‚   â”‚   â”‚       â”œâ”€â”€ anthropic.py     # Claude implementation
â”‚   â”‚   â”‚       â”œâ”€â”€ openai.py        # OpenAI GPT implementation
â”‚   â”‚   â”‚       â””â”€â”€ ollama.py        # Ollama implementation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ tts/                     # Text-to-Speech providers
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ interface.py         # TTS provider interface
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py           # TTS provider manager
â”‚   â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ kokoro.py        # Kokoro TTS implementation
â”‚   â”‚   â”‚       â””â”€â”€ piper.py         # Piper TTS implementation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ notifications/           # Notification providers
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ interface.py         # Notification provider interface
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py           # Notification provider manager
â”‚   â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â””â”€â”€ telegram.py      # Telegram implementation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ database/                # Database management
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ manager.py           # SQLite database manager
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ logging/                 # Logging infrastructure
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ logger.py            # Centralized logger
â”‚   â”‚
â”‚   â””â”€â”€ interfaces/                  # User interfaces
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ cli/                     # Command-line interface
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ manager.py           # CLI manager
â”‚           â”œâ”€â”€ command_pattern.py   # Command pattern implementation
â”‚           â””â”€â”€ commands/            # CLI commands
â”‚               â”œâ”€â”€ __init__.py
â”‚               â”œâ”€â”€ base.py          # Base command class
â”‚               â”œâ”€â”€ youtube.py       # YouTube commands
â”‚               â”œâ”€â”€ llm.py           # LLM commands
â”‚               â”œâ”€â”€ tts.py           # TTS commands
â”‚               â”œâ”€â”€ notify_test.py   # Notification test command
â”‚               â”œâ”€â”€ summary.py       # Summary commands
â”‚               â”œâ”€â”€ db_info.py       # Database info command
â”‚               â””â”€â”€ version.py       # Version command
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ llm_system.md                # LLM system documentation
â”‚   â”œâ”€â”€ tts_system.md                # TTS system documentation
â”‚   â”œâ”€â”€ youtube_system.md            # YouTube system documentation
â”‚   â””â”€â”€ summary_system.md            # Summary system documentation
â”‚
â””â”€â”€ cache_data/                      # Runtime data (gitignored)
    â”œâ”€â”€ youtube_transcripts/         # Cached transcripts
    â”œâ”€â”€ tts/                         # Generated audio files
    â””â”€â”€ state.db                     # SQLite database
```

## ğŸ—ï¸ Architecture

### Design Patterns

- **Provider Pattern**: Pluggable LLM, TTS, and notification providers
- **Command Pattern**: CLI commands with consistent interface
- **Manager Pattern**: Centralized management of providers and resources
- **Repository Pattern**: Database abstraction for state management

### Key Components

1. **Configuration Layer** ([`config/manager.py`](src/time_reclamation/config/manager.py:1))
   - YAML-based configuration with validation
   - Support for local overrides (config.local.yml)
   - Environment-specific settings

2. **Core Business Logic** ([`core/`](src/time_reclamation/core/))
   - Platform-specific implementations (YouTube, Reddit, Twitter)
   - Content extraction and processing
   - Summary generation orchestration

3. **Infrastructure Layer** ([`infrastructure/`](src/time_reclamation/infrastructure/))
   - LLM providers with unified interface
   - TTS engines for audio generation
   - Notification delivery systems
   - Database and logging utilities

4. **Interface Layer** ([`interfaces/cli/`](src/time_reclamation/interfaces/cli/))
   - Command-line interface with subcommands
   - User-friendly command structure
   - Error handling and feedback

## ğŸ”§ Technical Stack

- **Language**: Python 3.8+
- **Configuration**: PyYAML
- **Database**: SQLite3
- **LLM Integration**: 
  - llama-cpp-python (local GGUF models)
  - anthropic (Claude API)
  - openai (GPT API)
  - ollama (local/remote Ollama)
- **TTS**: 
  - kokoro (neural TTS)
  - piper-tts (lightweight TTS)
- **Video Processing**: yt-dlp
- **Notifications**: requests (Telegram Bot API)
- **Audio**: soundfile, numpy, torch


## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

